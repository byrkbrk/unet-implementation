{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcpzpwEE6ah22jJmqLxsxg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byrkbrk/unet-implementation/blob/main/unet_cell_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kCaT-fOJdVv"
      },
      "outputs": [],
      "source": [
        "# clone repository\n",
        "!git clone https://github.com/byrkbrk/unet-implementation.git\n",
        "!ls ./unet-implementation\n",
        "!cat ./unet-implementation/README.md\n",
        "\n",
        "# add directory to path\n",
        "import sys\n",
        "sys.path.append(\"./unet-implementation/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import modules\n",
        "from tqdm.auto import tqdm\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "from model import UNet\n",
        "from utils import crop, show_tensor_images\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "8FK5U7V2RbGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read input images as np array\n",
        "dir = \"./unet-implementation/\"\n",
        "volumes = io.imread(dir + \"train-volume.tif\")\n",
        "labels = io.imread(dir + \"train-labels.tif\")\n",
        "\n",
        "# print shapes\n",
        "print(\"volumes shape:\", volumes.shape)\n",
        "print(\"labels shape:\", labels.shape)\n",
        "\n",
        "# plot images\n",
        "plt.imshow(volumes[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "plt.imshow(labels[0], cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# check unique pixels\n",
        "print(\"volumes unique: \")\n",
        "print(np.unique(volumes[0]))\n",
        "print(\"labels unique: \")\n",
        "print(np.unique(labels[0]))\n"
      ],
      "metadata": {
        "id": "u-TDZ0WAbpc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to torch and normalize \n",
        "volumes = torch.Tensor(volumes)[:, None, :, :]/255\n",
        "labels = torch.Tensor(labels)[:, None, :, :]/255\n",
        "\n",
        "# crop labels\n",
        "target_dim = 373 # i.e. unet output shape: (-1, 1, 373, 373)\n",
        "labels = crop(labels, (labels.shape[0], labels.shape[1], target_dim, target_dim))\n",
        "\n",
        "# construct dataset\n",
        "dataset = torch.utils.data.TensorDataset(volumes, labels)\n"
      ],
      "metadata": {
        "id": "cZrzCOe0dukF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set dataloadaer\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# instantiate model\n",
        "unet = UNet(1, 1)\n",
        "unet.to(device)\n",
        "\n",
        "# define criterion\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# define optimizer\n",
        "optimizer = optim.Adam(unet.parameters(), lr=2e-4)\n"
      ],
      "metadata": {
        "id": "eBaC0_h-LVLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "n_epochs = 200\n",
        "display_step = 40\n",
        "cur_step = 0\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for mini_images, mini_labels in tqdm(dataloader):\n",
        "        mini_images = mini_images.to(device)\n",
        "        mini_labels = mini_labels.to(device)\n",
        "        preds = unet(mini_images)\n",
        "        loss = criterion(preds, mini_labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if cur_step % display_step == 0:\n",
        "            print(f\"Epoch: {epoch}, Steps: {cur_step}, Loss: {loss:.3f}\")\n",
        "            \n",
        "            # plot input images\n",
        "            show_tensor_images(\n",
        "                crop(mini_images, (mini_images.shape[0], 1, target_dim, target_dim)),\n",
        "                4,\n",
        "                size=(1, target_dim, target_dim)\n",
        "            )\n",
        "\n",
        "            # plot labels\n",
        "            show_tensor_images(mini_labels, 4, size=(1, target_dim, target_dim))\n",
        "            \n",
        "            # plot predictions\n",
        "            show_tensor_images(torch.sigmoid(preds), 4, size=(1, target_dim, target_dim))\n",
        "\n",
        "        cur_step += 1\n"
      ],
      "metadata": {
        "id": "y7c8VhukN2Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check performance on test dataset\n",
        "\n",
        "# read test volumes\n",
        "test_volumes = io.imread(dir + \"test-volume.tif\")\n",
        "test_volumes = torch.Tensor(test_volumes)[:, None, :, :]/255\n",
        "\n",
        "# get small test dataset portion\n",
        "mini_test_volumes = test_volumes[4:8]\n",
        "\n",
        "# get test predictions\n",
        "unet.eval().to(device=\"cpu\")\n",
        "test_preds = unet(mini_test_volumes)\n",
        "\n",
        "# plot images\n",
        "show_tensor_images(\n",
        "                crop(mini_test_volumes, (mini_test_volumes.shape[0], 1, target_dim, target_dim)),\n",
        "                4,\n",
        "                size=(1, target_dim, target_dim)\n",
        ")\n",
        "show_tensor_images(torch.sigmoid(test_preds), 4, size=(1, target_dim, target_dim))\n",
        "\n"
      ],
      "metadata": {
        "id": "wjiOzhWAXZam"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}